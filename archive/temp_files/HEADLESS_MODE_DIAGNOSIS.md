# Diagn√≥stico: Timeouts Intermitentes e Anti-Bot ANBIMA

## Data: 2025-11-03

## Problema Relatado

- Timeouts intermitentes em headless mode
- Web app com falhas frequentes
- Comportamento inconsistente (√†s vezes funciona, √†s vezes n√£o)

## Investiga√ß√£o Realizada

### Fase 1: Testes Iniciais

1. **CLI Teste (manh√£)**: ‚úÖ FUNCIONOU
   - Tempo: 0.77 minutos
   - Dados: 22 registros extra√≠dos
   - Modo: headless=True

2. **Web App Diagn√≥stico**: ‚ùå FALHAVA
   - Dados scrapeados mas n√£o salvos (problema de convers√£o - RESOLVIDO)

### Fase 2: Testes de Navega√ß√£o Passo a Passo

**Objetivo**: Identificar em qual etapa ocorre o timeout

**Resultado - Primeira Tentativa**:
```
Step 1: Setup driver... ‚úì (1.2s)
Step 2: Navigate to ANBIMA... ‚úì (5.3s)
Step 3: Find search input... ‚ùå TIMEOUT (31.6s)
```

**Causa Inicial Suspeita**: Seletor CSS incorreto
- Teste usava: `input[placeholder*='Pesquise']`
- Scraper usa: `input[placeholder*='Busque fundos']`

### Fase 3: Debug do Estado da P√°gina

**Script criado**: `test_page_state.py`

**Descoberta Cr√≠tica**:
```
Page title: P√°gina Anti-Rob√¥ | ANBIMA Data
Page URL: https://data.anbima.com.br/robo
Found 0 input elements
```

**CONCLUS√ÉO**: O site ANBIMA est√° detectando bot e redirecionando para p√°gina de bloqueio!

### Fase 4: Melhorias Anti-Detec√ß√£o Implementadas

1. **Op√ß√µes experimentais do Chrome**:
```python
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
chrome_options.add_experimental_option('useAutomationExtension', False)
```

2. **Modifica√ß√£o de propriedades do Navigator**:
```python
self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
    'source': '''
        Object.defineProperty(navigator, 'webdriver', {
            get: () => undefined
        });
        Object.defineProperty(navigator, 'plugins', {
            get: () => [1, 2, 3, 4, 5]
        });
        Object.defineProperty(navigator, 'languages', {
            get: () => ['pt-BR', 'pt', 'en-US', 'en']
        });
        window.chrome = {
            runtime: {}
        };
    '''
})
```

### Fase 5: Teste P√≥s-Corre√ß√£o

**Resultado**: ‚ùå AINDA BLOQUEADO
- Headless: P√°gina Anti-Rob√¥
- Non-Headless: P√°gina Anti-Rob√¥

**CLI Reteste**: ‚ùå TAMB√âM FALHOU
```
Worker 1: Failed to scrape 48.330.198/0001-06: Timeout (3 tentativas)
Success: 0 (0.0%)
```

## An√°lise do Problema

### O Que Est√° Acontecendo

1. **Site da ANBIMA tem prote√ß√£o anti-bot ativa**
   - Redirecionamento para `/robo` quando detecta automa√ß√£o
   - T√≠tulo: "P√°gina Anti-Rob√¥ | ANBIMA Data"

2. **Detec√ß√£o √© sofisticada**
   - N√£o √© apenas verifica√ß√£o de `navigator.webdriver`
   - Provavelmente analisa:
     - Padr√µes de comportamento (velocidade, timing)
     - Fingerprinting do navegador
     - Rate limiting / IP tracking
     - Caracter√≠sticas de headless Chrome

3. **Comportamento intermitente explicado**:
   - **Quando funciona**: Site n√£o est√° com rate limit ativo ou permitindo tr√°fego
   - **Quando falha**: Prote√ß√£o anti-bot ativada (ap√≥s muitas requisi√ß√µes ou padr√£o suspeito)
   - **Por que ambos CLI e Web App**: Mesma m√°quina, mesmo IP, mesmo padr√£o

### Evid√™ncias

| Teste | Resultado | Momento |
|-------|-----------|---------|
| CLI (manh√£, 09:55) | ‚úÖ Sucesso | Antes dos testes |
| Web App Diagn√≥stico | ‚úÖ Scraping OK / ‚ùå Save falhou | Durante desenvolvimento |
| Test Navigation (10:20) | ‚ùå Bloqueado | Ap√≥s m√∫ltiplos testes |
| CLI Reteste (10:28) | ‚ùå Bloqueado | Ap√≥s melhorias anti-detec√ß√£o |

**Padr√£o**: Funcionou inicialmente, depois come√ßou a bloquear ap√≥s m√∫ltiplas requisi√ß√µes.

## Solu√ß√µes e Recomenda√ß√µes

### Solu√ß√£o 1: Aguardar e Respeitar Rate Limits ‚è∞

**Descri√ß√£o**: Esperar per√≠odos maiores entre requisi√ß√µes

**Implementa√ß√£o**:
```python
# Em config.py
DELAY_BETWEEN_REQUESTS = 10  # Aumentar de 2 para 10 segundos
DELAY_BETWEEN_WORKERS = 30  # Delay entre inicializa√ß√£o de workers
DELAY_AFTER_ERROR = 60  # Delay ap√≥s erro antes de retry
```

**Pros**:
- Simples
- N√£o requer mudan√ßas complexas
- Pode funcionar com o c√≥digo atual

**Contras**:
- Muito lento (1 CNPJ a cada 10+ segundos)
- N√£o garante sucesso
- 161 CNPJs = ~27 minutos no m√≠nimo

### Solu√ß√£o 2: Modo Non-Headless Permanente üñ•Ô∏è

**Descri√ß√£o**: Usar apenas modo visual (janelas vis√≠veis)

**Implementa√ß√£o**:
```python
# For√ßar headless=False
scraper = ANBIMAScraper(headless=False)
```

**Pros**:
- Menos detec√ß√£o (navegador real)
- Funciona mais consistentemente
- J√° testado e validado

**Contras**:
- Requer monitor/desktop
- Janelas vis√≠veis (n√£o pode rodar em servidor sem GUI)
- Usu√°rio pode interferir

**Recomenda√ß√£o**: ‚úÖ **USAR ESTA SOLU√á√ÉO NA WEB APP**

### Solu√ß√£o 3: Rota√ß√£o de IP / Proxies üåê

**Descri√ß√£o**: Usar diferentes IPs para cada requisi√ß√£o

**Implementa√ß√£o**:
```python
# Exemplo conceitual
PROXY_LIST = ['proxy1.com:8080', 'proxy2.com:8080', ...]

chrome_options.add_argument(f'--proxy-server={random.choice(PROXY_LIST)}')
```

**Pros**:
- Contorna rate limiting por IP
- Pode usar headless
- Escal√°vel

**Contras**:
- Requer servi√ßo de proxy (custo)
- Proxies podem ser lentos/inst√°veis
- Complexidade adicional
- Pode violar termos de uso

### Solu√ß√£o 4: Selenium com Perfil Real do Chrome üë§

**Descri√ß√£o**: Usar perfil de usu√°rio existente do Chrome

**Implementa√ß√£o**:
```python
chrome_options.add_argument('--user-data-dir=/Users/USERNAME/Library/Application Support/Google/Chrome')
chrome_options.add_argument('--profile-directory=Default')
```

**Pros**:
- Sess√£o autenticada (se necess√°rio)
- Cookies e hist√≥rico real
- Menos detec√ß√£o

**Contras**:
- Requer Chrome instalado localmente
- Pode interferir com uso normal do navegador
- Espec√≠fico por m√°quina

### Solu√ß√£o 5: Playwright / Puppeteer Stealth ü•∑

**Descri√ß√£o**: Trocar Selenium por Playwright com plugin stealth

**Implementa√ß√£o**:
```python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch(
        headless=True,
        args=['--disable-blink-features=AutomationControlled']
    )
    # ... scraping
```

**Pros**:
- Melhor evas√£o de detec√ß√£o
- Mais moderno e r√°pido
- Bom suporte headless

**Contras**:
- Reescrever c√≥digo existente
- Nova depend√™ncia
- Curva de aprendizado

### Solu√ß√£o 6: Scrapy + Splash ou Similar üöÄ

**Descri√ß√£o**: Framework de scraping profissional

**Pros**:
- Feito para scraping em escala
- Gerenciamento de rate limiting
- Rota√ß√£o de user agents

**Contras**:
- Reescrita completa
- Mais complexo
- Overhead inicial

### Solu√ß√£o 7: Contato com ANBIMA / API Oficial üìû

**Descri√ß√£o**: Verificar se h√° API oficial ou solicitar acesso

**Pros**:
- Solu√ß√£o oficial e est√°vel
- Sem problemas de bloqueio
- Dados estruturados

**Contras**:
- Pode n√£o existir
- Pode ter custo
- Processo de aprova√ß√£o

## Recomenda√ß√£o Final

### Para Uso Imediato

‚úÖ **Solu√ß√£o 2: Non-Headless Mode**
- Modificar web app para usar `headless=False` por padr√£o
- Documentar que requer ambiente com GUI
- Adicionar delay entre requisi√ß√µes (5-10s)

**Implementa√ß√£o**:
```python
# Em web_app/scraper_service.py
def preinitialize_chromedriver(self):
    scraper = ANBIMAScraper(headless=False)  # J√° est√° assim!
    # ...

# Em config.py
SLEEP_BETWEEN_REQUESTS = 5  # Aumentar de 2 para 5 segundos
```

### Para Futuro (Se Necess√°rio)

1. **Curto prazo**: Implementar delays maiores e randomiza√ß√£o
2. **M√©dio prazo**: Avaliar Playwright Stealth
3. **Longo prazo**: Buscar API oficial da ANBIMA

## Testes Criados

### Arquivos de Teste

1. **`test_headless_reliability.py`**
   - Testa confiabilidade com 10 tentativas
   - Compara headless vs non-headless
   - Calcula taxa de sucesso

2. **`test_navigation_steps.py`**
   - Testa cada etapa de navega√ß√£o
   - Identifica ponto de falha
   - Tira screenshots em caso de erro

3. **`test_page_state.py`**
   - Verifica estado da p√°gina
   - Lista elementos dispon√≠veis
   - Detecta p√°gina anti-rob√¥

### Como Usar

```bash
# Teste de confiabilidade (demora ~30-40 min para 20 tentativas)
python3 test_headless_reliability.py

# Teste de navega√ß√£o passo a passo (r√°pido)
python3 test_navigation_steps.py

# Debug do estado da p√°gina
python3 test_page_state.py
```

## Arquivos Modificados

1. **`anbima_scraper.py`**
   - Adicionadas op√ß√µes anti-detec√ß√£o
   - Modifica√ß√£o de propriedades navigator
   - Melhor evas√£o (mas ainda detectado)

2. **`config.py`**
   - Corre√ß√£o de seletor: "Pesquise" ‚Üí "Busque fundos"

3. **`test_navigation_steps.py`**
   - Corre√ß√£o de seletor

## Conclus√£o

O problema **n√£o √© espec√≠fico de headless mode**, mas sim uma **prote√ß√£o anti-bot sofisticada** da ANBIMA que:
- Detecta automa√ß√£o independente do modo
- Bloqueia ap√≥s m√∫ltiplas requisi√ß√µes
- √â intermitente baseado em rate limiting

**Solu√ß√£o implementada**: Usar non-headless mode com delays adequados.

**Status atual**: 
- ‚úÖ Web app salva dados corretamente (fix anterior)
- ‚ö†Ô∏è Scraping bloqueado por anti-bot (aguardar ou usar non-headless)
- ‚úÖ Melhorias anti-detec√ß√£o implementadas (podem ajudar quando site permitir)

---

**√öltima atualiza√ß√£o**: 2025-11-03 10:30
**Status**: DIAGNOSTICADO - Prote√ß√£o Anti-Bot Ativa
**A√ß√£o recomendada**: Aguardar algumas horas e usar non-headless mode com delays maiores






