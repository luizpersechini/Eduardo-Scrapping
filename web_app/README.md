# ğŸŒ ANBIMA Data Scraper - Web Application

Interface web moderna para extraÃ§Ã£o automatizada de dados de fundos da ANBIMA.

---

## âœ¨ Recursos

- ğŸ“¤ **Upload de Arquivos Excel** - FaÃ§a upload de planilhas com CNPJs para scraping
- âš¡ **Processamento Paralelo** - Configure de 1 a 4 workers paralelos
- ğŸ“Š **Monitoramento em Tempo Real** - Acompanhe o progresso ao vivo com Socket.IO
- ğŸ’¾ **HistÃ³rico de Jobs** - Visualize todos os jobs executados
- ğŸ”„ **Retry AutomÃ¡tico** - Tente novamente CNPJs que falharam
- ğŸ“¥ **Download de Resultados** - Baixe os dados extraÃ­dos em formato Excel
- ğŸ¨ **Interface Moderna** - UI limpa e responsiva
- ğŸ“± **Mobile-Friendly** - Funciona perfeitamente em dispositivos mÃ³veis

---

## ğŸš€ Como Usar

### 1. InstalaÃ§Ã£o

Certifique-se de que todas as dependÃªncias estÃ£o instaladas:

```bash
# Do diretÃ³rio raiz do projeto
pip3 install -r requirements.txt
```

### 2. Iniciar o Servidor

**OpÃ§Ã£o A: Script automatizado (recomendado)**

```bash
# Do diretÃ³rio raiz do projeto
./start_web_app.sh
```

**OpÃ§Ã£o B: Manualmente**

```bash
cd web_app
python3 app.py
```

### 3. Acessar a AplicaÃ§Ã£o

Abra seu navegador e acesse:

```
http://localhost:5000
```

---

## ğŸ“– Guia de Uso

### Criando um Novo Job

1. **Upload do Arquivo**
   - Clique em "Selecione o arquivo Excel com CNPJs"
   - Escolha um arquivo `.xlsx` ou `.xls`
   - O arquivo deve ter uma coluna com CNPJs

2. **Configurar Workers**
   - Ajuste o nÃºmero de workers paralelos (1-4)
   - Recomendado: 4 workers (validado cientificamente)

3. **Criar Job**
   - Clique em "Upload e Criar Job"
   - Confirme se deseja iniciar o job imediatamente

### Monitorando o Progresso

Ao iniciar um job, vocÃª verÃ¡:

- **Barra de Progresso** - VisualizaÃ§Ã£o do progresso geral
- **EstatÃ­sticas em Tempo Real** - CNPJs processados, sucessos e falhas
- **Log ao Vivo** - Cada CNPJ sendo processado em tempo real
- **Fases do Processo**
  - PrÃ©-inicializaÃ§Ã£o do ChromeDriver
  - Teste de workers
  - Scraping
  - FinalizaÃ§Ã£o

### Resultados

Quando o job Ã© concluÃ­do:

1. **Download** - Baixe o arquivo Excel com os resultados
2. **Visualizar Detalhes** - Clique em um job para ver detalhes completos
3. **Retry** - Se houver falhas, tente novamente apenas os CNPJs que falharam

---

## ğŸ—„ï¸ Banco de Dados

A aplicaÃ§Ã£o usa **SQLite** para armazenar:

- **Jobs** - InformaÃ§Ãµes de cada job de scraping
- **CNPJs** - Status individual de cada CNPJ
- **Dados ExtraÃ­dos** - Valores histÃ³ricos de cotas

**LocalizaÃ§Ã£o do banco de dados:**
```
web_app/anbima_scraper.db
```

### Tabelas

#### `scraping_jobs`
- `id` - ID Ãºnico do job
- `filename` - Nome do arquivo original
- `status` - pending, running, completed, failed
- `total_cnpjs` - Total de CNPJs no job
- `successful_cnpjs` - CNPJs processados com sucesso
- `failed_cnpjs` - CNPJs que falharam
- `workers` - NÃºmero de workers usados
- `created_at` - Data de criaÃ§Ã£o
- `started_at` - Data de inÃ­cio
- `completed_at` - Data de conclusÃ£o
- `output_file` - Caminho do arquivo de saÃ­da

#### `cnpjs`
- `id` - ID Ãºnico
- `job_id` - ReferÃªncia ao job
- `cnpj` - NÃºmero do CNPJ
- `fund_name` - Nome do fundo
- `status` - pending, processing, success, failed, not_found
- `error_message` - Mensagem de erro (se aplicÃ¡vel)
- `retry_count` - NÃºmero de tentativas
- `data_count` - Quantidade de registros histÃ³ricos extraÃ­dos
- `scraped_at` - Data/hora da extraÃ§Ã£o

#### `scraped_data`
- `id` - ID Ãºnico
- `cnpj_id` - ReferÃªncia ao CNPJ
- `cnpj` - NÃºmero do CNPJ
- `fund_name` - Nome do fundo
- `date` - Data da cotaÃ§Ã£o
- `value` - Valor da cota
- `created_at` - Data de criaÃ§Ã£o do registro

---

## ğŸ”Œ API Endpoints

### Jobs

- `GET /api/jobs` - Lista todos os jobs
- `GET /api/jobs/<job_id>` - Detalhes de um job especÃ­fico
- `GET /api/jobs/<job_id>/failed` - Lista CNPJs que falharam
- `POST /api/jobs/<job_id>/start` - Inicia um job
- `POST /api/jobs/<job_id>/retry` - Tenta novamente CNPJs que falharam
- `GET /api/jobs/<job_id>/download` - Download dos resultados

### Upload

- `POST /api/upload` - Upload de arquivo Excel com CNPJs

### EstatÃ­sticas

- `GET /api/stats` - EstatÃ­sticas gerais da aplicaÃ§Ã£o

---

## ğŸ”„ Socket.IO Events

### Client â†’ Server

- `connect` - Conecta ao servidor
- `disconnect` - Desconecta do servidor

### Server â†’ Client

- `connected` - ConfirmaÃ§Ã£o de conexÃ£o
- `job_update` - AtualizaÃ§Ã£o de progresso do job
  ```json
  {
    "job_id": 1,
    "status": "running",
    "progress": 45.5,
    "successful": 50,
    "failed": 5,
    "message": "Processando...",
    "timestamp": "2024-10-31T12:00:00"
  }
  ```

- `cnpj_update` - AtualizaÃ§Ã£o de status de um CNPJ
  ```json
  {
    "job_id": 1,
    "cnpj": "12.345.678/0001-90",
    "status": "success",
    "timestamp": "2024-10-31T12:00:00"
  }
  ```

---

## ğŸ¨ Interface

### SeÃ§Ãµes Principais

1. **Header com EstatÃ­sticas**
   - Total de jobs
   - Jobs completados
   - Jobs em andamento
   - CNPJs extraÃ­dos

2. **Novo Job**
   - Upload de arquivo
   - ConfiguraÃ§Ã£o de workers
   - BotÃ£o de criaÃ§Ã£o

3. **Job em Andamento**
   - Progresso em tempo real
   - EstatÃ­sticas de sucesso/falha
   - Log ao vivo

4. **HistÃ³rico de Jobs**
   - Lista de todos os jobs
   - AÃ§Ãµes por job (iniciar, download, retry)
   - VisualizaÃ§Ã£o de detalhes

---

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **Flask** - Framework web
- **Flask-SQLAlchemy** - ORM para banco de dados
- **Flask-SocketIO** - ComunicaÃ§Ã£o em tempo real
- **SQLite** - Banco de dados
- **Selenium** - Web scraping
- **Pandas** - Processamento de dados

### Frontend
- **HTML5** - Estrutura
- **CSS3** - EstilizaÃ§Ã£o moderna
- **JavaScript (ES6+)** - LÃ³gica e interaÃ§Ãµes
- **Socket.IO Client** - ComunicaÃ§Ã£o em tempo real
- **Font Awesome** - Ãcones

---

## ğŸ“ Estrutura de Arquivos

```
web_app/
â”œâ”€â”€ app.py                      # AplicaÃ§Ã£o Flask principal
â”œâ”€â”€ models.py                   # Modelos de banco de dados
â”œâ”€â”€ scraper_service.py          # ServiÃ§o de scraping integrado
â”œâ”€â”€ anbima_scraper.db           # Banco de dados SQLite (criado automaticamente)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # PÃ¡gina principal
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # Estilos
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js            # JavaScript principal
â”œâ”€â”€ uploads/                    # Arquivos Excel enviados (criado automaticamente)
â””â”€â”€ outputs/                    # Resultados gerados (criado automaticamente)
```

---

## ğŸ”’ SeguranÃ§a

- âœ… Limite de tamanho de arquivo (16MB)
- âœ… ValidaÃ§Ã£o de tipo de arquivo (apenas Excel)
- âœ… SanitizaÃ§Ã£o de nomes de arquivo
- âœ… Isolamento de uploads e outputs

---

## ğŸš€ Deploy (Futuro)

Para deploy em produÃ§Ã£o, considere:

1. **Usar um servidor WSGI** (Gunicorn, uWSGI)
2. **Proxy reverso** (Nginx, Apache)
3. **Banco de dados robusto** (PostgreSQL)
4. **VariÃ¡veis de ambiente** para configuraÃ§Ãµes sensÃ­veis
5. **HTTPS** para comunicaÃ§Ã£o segura
6. **AutenticaÃ§Ã£o** para acesso restrito

---

## ğŸ› Troubleshooting

### Problema: Porta 5000 jÃ¡ em uso

**SoluÃ§Ã£o:** Mude a porta em `app.py`:

```python
socketio.run(app, host='0.0.0.0', port=5001, debug=True)
```

### Problema: Erro ao conectar ao ChromeDriver

**SoluÃ§Ã£o:** A aplicaÃ§Ã£o prÃ©-inicializa o ChromeDriver. Se persistir:

1. Limpe o cache do ChromeDriver
2. Reduza o nÃºmero de workers
3. Verifique a memÃ³ria do sistema

### Problema: Jobs nÃ£o aparecem

**SoluÃ§Ã£o:** 
- Recarregue a pÃ¡gina
- Verifique o console do navegador (F12)
- Verifique os logs do servidor

---

## ğŸ“ Logs

Os logs sÃ£o salvos em:

```
logs/scraper_parallel_YYYYMMDD_HHMMSS.log
```

---

## ğŸ¯ PrÃ³ximas Funcionalidades

- [ ] AutenticaÃ§Ã£o de usuÃ¡rios
- [ ] Agendamento de jobs
- [ ] NotificaÃ§Ãµes por email
- [ ] Dashboard de analytics
- [ ] ExportaÃ§Ã£o em mÃºltiplos formatos
- [ ] API REST completa
- [ ] Temas claro/escuro
- [ ] ComparaÃ§Ã£o de resultados

---

## ğŸ’¡ Dicas

1. **Performance**: Use 4 workers para melhor performance/estabilidade
2. **CNPJs Grandes**: Para listas muito grandes (500+), considere dividir em jobs menores
3. **Retry**: Sempre tente novamente os CNPJs que falharam - pode ser problema temporÃ¡rio do site
4. **Backup**: FaÃ§a backup do banco de dados periodicamente
5. **Limpeza**: Remova jobs e dados antigos periodicamente

---

## ğŸ“ Suporte

Para problemas ou sugestÃµes, consulte a documentaÃ§Ã£o principal do projeto.

---

**Status:** âœ… **PRODUCTION READY**  
**VersÃ£o:** 1.0.0  
**Data:** Novembro 2024







