# Web UI Implementation Plan - Phase 3

**Goal:** Create a simple web interface for non-technical users to scrape ANBIMA data
**Deployment:** Streamlit Cloud (free, deploy from GitHub)
**Target User:** Friend who needs to scrape data a couple times per month

---

## ğŸ¯ Project Requirements

### Must Have
- âœ… Upload Excel file with CNPJs
- âœ… One-click scraping start
- âœ… Real-time progress display
- âœ… Download results as Excel
- âœ… No coding knowledge required
- âœ… Accessible via URL (online)
- âœ… Deploy from GitHub automatically

### Nice to Have
- ğŸ“§ Email notification when complete
- ğŸ“Š Historical scraping records
- ğŸ” Simple password protection
- ğŸ“± Mobile-friendly interface
- ğŸ“ˆ Statistics dashboard

---

## ğŸ—ï¸ Architecture

### Technology Stack
```
Frontend:     Streamlit (Python-based web UI)
Backend:      Existing scrapers (stealth_scraper.py)
Deployment:   Streamlit Cloud (free tier)
Storage:      Temporary session storage
CI/CD:        Automatic from GitHub push
```

### File Structure
```
Eduardo-Scrapping/
â”œâ”€â”€ streamlit_app.py          # Main UI application (NEW)
â”œâ”€â”€ streamlit_utils.py         # Helper functions for UI (NEW)
â”œâ”€â”€ requirements_streamlit.txt # Streamlit dependencies (NEW)
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml           # Streamlit configuration (NEW)
â”œâ”€â”€ stealth_scraper.py        # Existing scraper (reuse)
â”œâ”€â”€ main_parallel.py          # Existing logic (reuse)
â”œâ”€â”€ config.py                 # Existing config (reuse)
â””â”€â”€ README_DEPLOYMENT.md      # Deployment guide (NEW)
```

---

## ğŸ“‹ Implementation Steps

### Step 1: Create Streamlit App (streamlit_app.py)

**Main Components:**
1. **Header Section**
   - App title and description
   - Instructions for user

2. **File Upload Section**
   - Excel file uploader
   - CNPJ preview table
   - Validation (check file format)

3. **Scraping Control Section**
   - "Start Scraping" button
   - Settings (optional): workers, headless mode
   - Clear warnings/status

4. **Progress Display Section**
   - Progress bar (0-100%)
   - Current CNPJ being scraped
   - Success/Failed counters
   - Time elapsed
   - ETA (estimated time remaining)

5. **Results Section**
   - Success message
   - Download button for Excel results
   - Summary statistics

6. **Error Handling**
   - User-friendly error messages
   - Retry button
   - Help/FAQ section

### Step 2: Adapt Existing Scraper for Streamlit

**Modifications needed:**
```python
# Instead of printing to console:
print("Processing...")

# Use Streamlit components:
st.progress(0.5)
st.write("Processing...")
```

**Key Changes:**
- Replace `tqdm` progress bars with `st.progress()`
- Replace `print()` with `st.write()` or `st.info()`
- Add session state for progress tracking
- Store results in memory (st.session_state)

### Step 3: Configure Streamlit Cloud

**Requirements:**
1. GitHub repository (âœ… already have)
2. Streamlit Cloud account (free)
3. Configuration files

**Files needed:**
- `requirements.txt` - All Python dependencies
- `.streamlit/config.toml` - App configuration
- `packages.txt` - System packages (for Chrome)

### Step 4: Handle Chrome/Selenium in Cloud

**Challenge:** Streamlit Cloud doesn't have Chrome by default

**Solutions:**
1. **Option A: Use undetected-chromedriver-auto**
   - Auto-downloads Chrome binary
   - Works in cloud environments
   - Already using in stealth mode

2. **Option B: Use Selenium Grid (external)**
   - BrowserStack/Sauce Labs
   - More reliable but costs money

3. **Option C: Use Parse.bot API**
   - No Chrome needed (API-based)
   - Most reliable for cloud
   - Small cost but guaranteed to work

**Recommendation:** Try Option A first, fallback to Option C if needed

### Step 5: Deploy to Streamlit Cloud

**Deployment Process:**
1. Push code to GitHub
2. Go to https://share.streamlit.io/
3. Connect GitHub account
4. Select repository: `luizpersechini/Eduardo-Scrapping`
5. Set main file: `streamlit_app.py`
6. Deploy (automatic)
7. Get URL: `https://eduardo-scrapping.streamlit.app/`

**Configuration:**
- Python version: 3.9+
- Branch: main
- Auto-deploy: ON (deploys on git push)

---

## ğŸ¨ UI Mockup (Text-based)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                   â”‚
â”‚  ğŸ¦ ANBIMA Fund Data Scraper                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•        â”‚
â”‚                                                                   â”‚
â”‚  Welcome! Upload your CNPJ list and start scraping ANBIMA data. â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“¤ Step 1: Upload CNPJ List                               â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  [Browse Files]  or  [Drag & Drop Excel File]            â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â„¹ï¸  Use the template file: input_valid_cnpjs.xlsx       â”‚  â”‚
â”‚  â”‚     (36 validated CNPJs included)                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“‹ Preview: 36 CNPJs loaded                               â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  CNPJ                  Status                             â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚  â”‚
â”‚  â”‚  13.054.728/0001-48    âœ“ Valid                           â”‚  â”‚
â”‚  â”‚  15.585.932/0001-10    âœ“ Valid                           â”‚  â”‚
â”‚  â”‚  17.313.316/0001-36    âœ“ Valid                           â”‚  â”‚
â”‚  â”‚  ... (show first 5)                                       â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  [View All CNPJs â–¼]                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âš™ï¸  Settings                                              â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â˜ Stealth Mode (Recommended)          [ON]              â”‚  â”‚
â”‚  â”‚  Workers:                               [1] (Conservative)â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  [ğŸš€ Start Scraping]                                             â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“Š Progress                                                â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 65% Complete                   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  Currently scraping: 26.841.302/0001-86                   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  âœ“ Success: 23 | âŒ Failed: 0 | â±ï¸ Time: 52 min          â”‚  â”‚
â”‚  â”‚  ğŸ“ˆ ETA: 28 minutes remaining                             â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  Latest Activity:                                         â”‚  â”‚
â”‚  â”‚  âœ“ 17.313.316/0001-36 - Completed (22 data points)       â”‚  â”‚
â”‚  â”‚  âœ“ 15.585.932/0001-10 - Completed (22 data points)       â”‚  â”‚
â”‚  â”‚  âš™ï¸ 26.841.302/0001-86 - In progress...                  â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âœ… Scraping Complete!                                      â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  ğŸ“Š Results:                                              â”‚  â”‚
â”‚  â”‚     â€¢ Total CNPJs: 36                                     â”‚  â”‚
â”‚  â”‚     â€¢ Successful: 36 (100%)                               â”‚  â”‚
â”‚  â”‚     â€¢ Failed: 0                                           â”‚  â”‚
â”‚  â”‚     â€¢ Total time: 1 hour 20 minutes                       â”‚  â”‚
â”‚  â”‚     â€¢ Data points: 792 (36 funds Ã— 22 dates avg)         â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  [â¬‡ï¸  Download Results (Excel)]                           â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  ğŸ“§ Email results? [Enter email] [Send]                   â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚  â„¹ï¸  Help | ğŸ“– Documentation | ğŸ› Report Issue                  â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Implementation Details

### Session State Management
```python
# streamlit_app.py
import streamlit as st

# Initialize session state
if 'scraping_in_progress' not in st.session_state:
    st.session_state.scraping_in_progress = False
    st.session_state.progress = 0
    st.session_state.results = None
    st.session_state.cnpjs = []
```

### Progress Updates
```python
# Callback function for scraper progress
def update_progress(current, total, cnpj, status):
    st.session_state.progress = current / total
    st.session_state.current_cnpj = cnpj
    st.session_state.status = status
    # Force UI refresh
    st.rerun()
```

### File Handling
```python
# Upload handling
uploaded_file = st.file_uploader("Upload CNPJ List", type=['xlsx'])
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.session_state.cnpjs = df['CNPJ'].tolist()
```

### Download Results
```python
# When scraping complete
if st.session_state.results:
    excel_buffer = io.BytesIO()
    st.session_state.results.to_excel(excel_buffer)

    st.download_button(
        label="Download Results",
        data=excel_buffer,
        file_name=f"anbima_results_{datetime.now():%Y%m%d_%H%M%S}.xlsx",
        mime="application/vnd.ms-excel"
    )
```

---

## ğŸš€ Deployment Checklist

### Pre-Deployment
- [ ] Create `streamlit_app.py`
- [ ] Create `streamlit_utils.py`
- [ ] Update `requirements.txt` with Streamlit
- [ ] Create `.streamlit/config.toml`
- [ ] Create `packages.txt` for system dependencies
- [ ] Test locally: `streamlit run streamlit_app.py`
- [ ] Commit and push to GitHub

### Streamlit Cloud Setup
- [ ] Create Streamlit Cloud account (https://share.streamlit.io/)
- [ ] Connect GitHub account
- [ ] Select repository: Eduardo-Scrapping
- [ ] Configure deployment:
  - Main file: `streamlit_app.py`
  - Python version: 3.9+
  - Branch: main
- [ ] Deploy
- [ ] Test deployed app
- [ ] Share URL with friend

### Post-Deployment
- [ ] Create user guide (screenshots + instructions)
- [ ] Test from different devices/browsers
- [ ] Monitor usage/errors (Streamlit Analytics)
- [ ] Setup error notifications (optional)
- [ ] Document troubleshooting steps

---

## ğŸ’° Cost Analysis

### Streamlit Cloud Free Tier
- **Cost:** $0/month
- **Includes:**
  - 1 private app OR unlimited public apps
  - 1 GB RAM
  - 2 CPU cores
  - Community support

**Sufficient for:**
- Monthly scraping sessions (couple times per month)
- 36 CNPJs per run (~1.5 hours)
- Single user (your friend)

### If Free Tier is Insufficient
**Streamlit Cloud Starter:** $20/month
- 3 private apps
- More resources
- Priority support

**Alternative:** Self-host on your server (free but requires maintenance)

---

## ğŸ” Security Considerations

### Authentication
**Option 1:** No authentication (app is publicly accessible)
- Simple URL
- Anyone with link can use
- âš ï¸ Risk: Others could use your resources

**Option 2:** Simple password (Streamlit built-in)
```python
import hmac
import streamlit as st

def check_password():
    def password_entered():
        if hmac.compare_digest(st.session_state["password"], "your_secret"):
            st.session_state["password_correct"] = True
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.text_input("Password", type="password", on_change=password_entered, key="password")
        return False

    return st.session_state["password_correct"]

if not check_password():
    st.stop()
```

**Option 3:** GitHub OAuth (Streamlit Teams feature)
- Requires paid plan
- Most secure

**Recommendation:** Start with Option 1 (no auth), add Option 2 if needed

### Data Privacy
- âœ… Results stored only in session (temporary)
- âœ… No data persistence (unless user downloads)
- âœ… Files deleted after session ends
- âš ï¸ Consider: Don't log sensitive CNPJ data

---

## ğŸ“Š Testing Strategy

### Local Testing
```bash
# Install Streamlit
pip install streamlit

# Run locally
streamlit run streamlit_app.py

# Open browser: http://localhost:8501
```

### Test Cases
1. âœ… Upload valid Excel file â†’ Should preview CNPJs
2. âœ… Upload invalid file â†’ Should show error
3. âœ… Start scraping â†’ Should show progress
4. âœ… Complete scraping â†’ Should enable download
5. âœ… Download results â†’ Should get valid Excel
6. âŒ Rate limiting â†’ Should handle gracefully
7. âŒ Network error â†’ Should show retry option
8. âŒ Chrome crash â†’ Should restart/retry

---

## ğŸ“ User Guide (for your friend)

### Quick Start
1. Go to: `https://eduardo-scrapping.streamlit.app/`
2. Click "Upload CNPJ List"
3. Select `input_valid_cnpjs.xlsx` (or your own list)
4. Click "Start Scraping"
5. Wait for completion (shows progress bar)
6. Click "Download Results"
7. Open Excel file with data

### Troubleshooting
**Problem:** Upload fails
**Solution:** Make sure file is .xlsx format with "CNPJ" column

**Problem:** Scraping stuck
**Solution:** Refresh page and try again (or report issue)

**Problem:** Download not working
**Solution:** Check browser allows downloads, try different browser

---

## ğŸ“ˆ Future Enhancements

### Phase 3.1 (Nice to Have)
- [ ] Email notifications when scraping completes
- [ ] Historical scraping records/dashboard
- [ ] Scheduling (automatic monthly scraping)
- [ ] Export to Google Sheets (instead of download)

### Phase 3.2 (Advanced)
- [ ] Multi-user support with accounts
- [ ] API endpoint for programmatic access
- [ ] Integration with Parse.bot as fallback
- [ ] Real-time charts/visualizations
- [ ] Mobile app (Progressive Web App)

---

## ğŸ¯ Success Criteria

### MVP (Minimum Viable Product)
- âœ… User can upload CNPJ list
- âœ… User can start scraping with one click
- âœ… User can see progress in real-time
- âœ… User can download results
- âœ… Works on desktop and mobile browsers
- âœ… Accessible via URL (no installation)

### Definition of Done
- âœ… Deployed to Streamlit Cloud
- âœ… URL shared with friend
- âœ… Friend successfully scraped data
- âœ… User guide created
- âœ… No errors during first use

---

## ğŸ—“ï¸ Timeline Estimate

**Total:** 4-6 hours

- **Planning:** 30 minutes âœ… (this document)
- **Development:** 2-3 hours
  - Streamlit app: 1.5 hours
  - Scraper integration: 1 hour
  - Testing: 30 minutes
- **Deployment:** 1 hour
  - Streamlit Cloud setup: 30 minutes
  - Testing deployed app: 30 minutes
- **Documentation:** 1 hour
  - User guide: 30 minutes
  - README updates: 30 minutes
- **Buffer:** 1 hour (for unexpected issues)

---

**Next Steps:**
1. Review this plan
2. Decide on deployment platform (Streamlit recommended)
3. Start implementing `streamlit_app.py`
4. Test locally
5. Deploy to Streamlit Cloud
6. Share URL with friend

**Status:** Ready to implement
**Priority:** High (friend needs monthly scraping)
